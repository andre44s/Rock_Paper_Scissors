{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rockpaperscisorV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYbZaXVyLlf"
      },
      "source": [
        "# Import TensorFlow library\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtE2KgdGy72j"
      },
      "source": [
        "# Download rock paper scissors dataset\n",
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta1hqfM1zbk3"
      },
      "source": [
        "# Import library untuk mengolah dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip dataset dari zip\n",
        "zip_location = '/tmp/rockpaperscissors.zip'\n",
        "zip_extract = zipfile.ZipFile(zip_location, 'r')\n",
        "zip_extract.extractall('/tmp')\n",
        "zip_extract.close()\n",
        "\n",
        "# Utilitas untuk membersihkan folder rockpaperscissors/rps-cv-images\n",
        "os.remove('/tmp/rockpaperscissors/rps-cv-images/README_rpc-cv-images.txt')\n",
        "base_dir = ('/tmp/rockpaperscissors/rps-cv-images/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mWPMs_WbWKn"
      },
      "source": [
        "# Import ImageDataGenerator untuk augmentasi gambar\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Mengatur parameter untuk augmentasi gambar\n",
        "# Membagi dataset ke train dan validation set sebesar 60/40\n",
        "base_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.5, 1.0),\n",
        "    shear_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.4)\n",
        "\n",
        "# Generator untuk training\n",
        "train_generator = base_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Generator untuk validation\n",
        "valid_generator = base_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQGICc-6mVSm"
      },
      "source": [
        "# Deklarasi class callback untuk stop training \n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > 0.96 and logs.get('val_accuracy') > 0.96):\n",
        "            print(\"\\nAccuracy is Optimal\")\n",
        "            self.model.stop_training = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhSxTBs2zu-2"
      },
      "source": [
        "# Membuat model dengan sequential, convolution, pooling, dropout dan dense\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD-E6A7WgT2B"
      },
      "source": [
        "# Membuat instansi callback untuk stop training\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Compile model dengan loss dan optimizer\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='Adamax',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Melihat summary dari model\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOgy7fUTgUi8"
      },
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=20,\n",
        "    epochs=50,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=10,\n",
        "    verbose=1,\n",
        "    callbacks=[callbacks]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr7zEfZ3mOSw"
      },
      "source": [
        "# Code untuk keperluan prediksi model\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUwRTV4VzqcB"
      },
      "source": [
        "# Percobaan\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    path = fn\n",
        "    img = image.load_img(path, target_size=(128, 128))\n",
        "    imgplot = plt.imshow(img)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "\n",
        "if classes[0][0] > classes[0][1]:\n",
        "    if classes[0][0] > classes[0][2]:\n",
        "        print('Paper')\n",
        "    else:\n",
        "        print('Scissors')\n",
        "else:\n",
        "    if classes[0][1] > classes[0][2]:\n",
        "        print('Rock')\n",
        "    else:\n",
        "        print('Scissors')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}